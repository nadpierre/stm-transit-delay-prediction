{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056758cb",
   "metadata": {},
   "source": [
    "# STM Transit Delay Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8706868",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d911d34",
   "metadata": {},
   "source": [
    "This notebook cleans and merges data collected from [STM](https://www.stm.info/en/about/developers) and [Open-Meteo](https://open-meteo.com/en/docs) and prepares it for data analysis and/or preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc184d",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e04ef",
   "metadata": {},
   "source": [
    "### STM Schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31f7ab",
   "metadata": {},
   "source": [
    "`trip_id`: Unique identifier for the transit trip.<br>\n",
    "`arrival_time`, `departure_time`: Scheduled arrival and departure time.<br>\n",
    "`stop_id`: Unique identifier of a stop.<br>\n",
    "`stop_sequence`: Sequence of a stop, for ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc749154",
   "metadata": {},
   "source": [
    "### STM Stops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b660a",
   "metadata": {},
   "source": [
    "`stop_id`: Unique identifier of a stop.<br>\n",
    "`stop_code`: Bus stop or metro station number.<br>\n",
    "`stop_name`: Bus stop or metro station name<br>\n",
    "`stop_lat`, `stop_lon`: Stop coordinates.<br>\n",
    "`stop_url`: Stop web page.<br>\n",
    "`location_type`: Stop type.<br>\n",
    "`parent_station`: Parent station (metro station with multiple exits).<br>\n",
    "`wheelchair_boarding`: Indicates if the stop is accessible for people in wheelchair, 0 meaning \"no information\", 1 being \"accessible\" and 2 being \"not accessible\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9173706",
   "metadata": {},
   "source": [
    "### STM Trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0019b7",
   "metadata": {},
   "source": [
    "`route_id`:  Unique identifier for the bus or metro line.<br>\n",
    "`service_id`: Identifies a set of dates when service is available for one or more routes.<br>\n",
    "`trip_id`: Unique identifier for the transit trip.<br>\n",
    "`trip_headsign`: Direction of the trip (Nord, South, West, East).<br>\n",
    "`direction_id`: Boolean value for the direction.<br>\n",
    "`shape_id`: Identifies a geospatial shape describing the vehicle travel path for a trip.\n",
    "`wheelchair_accessible`: Indicates wheelchair accessibility, 0 meaning \"no information\", 1 being \"accessible\" and 2 being \"not accessible\".<br>\n",
    "`note_fr`, `note_en`: Additionnal comment in French and English."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7358fab",
   "metadata": {},
   "source": [
    "### STM Real-Time Trip Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c2ee8a",
   "metadata": {},
   "source": [
    "`current_time`: Timestamp when the data was fetched from the GTFS, in milliseconds.<br>\n",
    "`trip_id`: Unique identifier for the transit trip.<br>\n",
    "`route_id`: Unique identifier for a bus or metro line.<br>\n",
    "`start_date`: Start date of the transit trip.<br>\n",
    "`stop_id`: Unique identifier of a stop.<br>\n",
    "`arrival_time`, `departure_time`: Realtime arrival and departure time, in seconds<br>\n",
    "`schedule_relationship`: State of the trip, 0 meaning \"scheduled\", 1 meaning \"skipped\" and 2 meaning \"no data\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1769aa78",
   "metadata": {},
   "source": [
    "### STM Route Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27dd6d9",
   "metadata": {},
   "source": [
    "`route_id`: Unique identifier for a bus or metro line.<br>\n",
    "`route_type`: Type of bus line (e.g. Night)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042db663",
   "metadata": {},
   "source": [
    "### Open-Meteo Weather Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccfdc47",
   "metadata": {},
   "source": [
    "`time`: Date and hour or the weather.<br>\n",
    "`temperature_2m`: Air temperature at 2 meters above ground, in Celsius.<br>\n",
    "`relative_humidity_2m`: Relative humidity at 2 meters above ground, in percentage.<br>\n",
    "`precipitation`: Total precipitation (rain, showers, snow) sum of the preceding hour, in millimeters.<br>\n",
    "`pressure`: Atmospheric air pressure reduced to mean sea level (msl), in hPa.<br>\n",
    "`cloud_cover`: Total cloud cover as an area fraction.<br>\n",
    "`windspeed_10m`: Wind speed at 10 meters above ground, in kilometers per hour.<br>\n",
    "`wind_direction_10m`: Wind direction at 10 meters above ground.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca39527",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7cafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad2700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom code\n",
    "sys.path.insert(0, '..')\n",
    "from scripts.custom_functions import fetch_weather, LOCAL_TIMEZONE, SCHEDULE_RELATIONSHIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786cc667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "schedules_df = pd.read_csv('../data/download/stop_times_2025-04-30.txt')\n",
    "stops_df = pd.read_csv('../data/download/stops_2025-04-30.txt')\n",
    "trips_df = pd.read_csv('../data/download/trips_2025-04-30.txt')\n",
    "trip_updates_df = pd.read_csv('../data/api/fetched_stm_trip_updates.csv', low_memory=False)\n",
    "routes_df = pd.read_csv('../data/route_types.csv')\n",
    "weather_df = pd.read_csv('../data/api/fetched_historical_weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3864f9b",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d79ac",
   "metadata": {},
   "source": [
    "### Schedules and stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4434500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values by stop sequence\n",
    "schedules_df = schedules_df.sort_values(by=['trip_id', 'stop_sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176567e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add trip progress (vehicles further along the trip are more likely to be delayed)\n",
    "total_stops = schedules_df.groupby('trip_id')['stop_id'].transform('count')\n",
    "schedules_df['trip_progress'] = schedules_df['stop_sequence'] / total_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8adfad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distribution of trip progress\n",
    "schedules_df['trip_progress'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f856eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge schedules and stops\n",
    "schedules_stops_df = pd.merge(left=schedules_df, right=stops_df, how='inner', left_on='stop_id', right_on='stop_code') \\\n",
    "\t.rename(columns={'stop_id_x': 'stop_id'}) \\\n",
    "\t.drop(['stop_id_y', 'stop_code', 'stop_url'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47cb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates of previous stop\n",
    "schedules_stops_df = schedules_stops_df.sort_values(by=['trip_id', 'stop_sequence'])\n",
    "schedules_stops_df['prev_lat'] = schedules_stops_df.groupby('trip_id')['stop_lat'].shift(1)\n",
    "schedules_stops_df['prev_lon'] = schedules_stops_df.groupby('trip_id')['stop_lon'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure scheduled arrival time has no null values\n",
    "assert schedules_stops_df['arrival_time'].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get arrival and departure time of previous stop\n",
    "schedules_stops_df['prev_time'] = schedules_stops_df.groupby('trip_id')['arrival_time'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44a7ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the null coordinates are from first stops\n",
    "prev_null_mask = (schedules_stops_df['prev_lat'].isna()) | (schedules_stops_df['prev_lon'].isna())\n",
    "first_stop_mask = schedules_stops_df['stop_sequence'] == 1\n",
    "assert prev_null_mask.sum() == first_stop_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987bd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gtfs_time(df:pd.DataFrame, date_column:str, time_column:str, milliseconds:bool=True) -> pd.Series:\n",
    "\t'''\n",
    "\tConverts GTFS time string (e.g., '25:30:00') to localized datetime\n",
    "\tbased on the arrival or departure time.\n",
    "\t'''\n",
    "\ttime_columns = ['hours', 'minutes', 'seconds']\n",
    "\tsplit_cols = df[time_column].str.split(':', expand=True).apply(pd.to_numeric)\n",
    "\tsplit_cols.columns = time_columns\n",
    "\tseconds_delta = (split_cols['hours'] * 3600) + (split_cols['minutes'] * 60) + split_cols['seconds']\n",
    "\t\n",
    "\t# Convert datetime to seconds\n",
    "\tif milliseconds:\n",
    "\t\tstart_seconds = df[date_column].astype('int') / 10**9\n",
    "\telse:# microseconds\n",
    "\t\tstart_seconds = df[date_column].astype('int') / 10**6\n",
    "\n",
    "\t# Add seconds \n",
    "\ttotal_seconds = start_seconds + seconds_delta\n",
    "\n",
    "\t# Convert to datetime\n",
    "\tparsed_time = pd.to_datetime(total_seconds, origin='unix', unit='s').dt.tz_localize(LOCAL_TIMEZONE)\n",
    "\n",
    "\treturn parsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae948b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with current date\n",
    "schedules_stops_df['today'] = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff0e87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse arrival time\n",
    "schedules_stops_df['parsed_time'] = parse_gtfs_time(schedules_stops_df, 'today', 'arrival_time', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c4e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse previous arrival time\n",
    "schedules_stops_df['parsed_prev_time'] = parse_gtfs_time(schedules_stops_df, 'today', 'prev_time', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ecf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected trip duration\n",
    "schedules_stops_df['trip_start'] = schedules_stops_df.groupby('trip_id')['parsed_time'].transform('min')\n",
    "schedules_stops_df['trip_end'] = schedules_stops_df.groupby('trip_id')['parsed_time'].transform('max')\n",
    "schedules_stops_df['exp_trip_duration'] = (schedules_stops_df['trip_end'] - schedules_stops_df['trip_start']) / pd.Timedelta(seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distribution\n",
    "schedules_stops_df['exp_trip_duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03624e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected delay between previous and current stop\n",
    "schedules_stops_df['exp_delay_prev_stop'] = (schedules_stops_df['parsed_time'] - schedules_stops_df['parsed_prev_time']) / pd.Timedelta(seconds=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distribution\n",
    "schedules_stops_df['exp_delay_prev_stop'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert that the null values are from first stops\n",
    "assert (schedules_stops_df['stop_sequence'] == 1).sum() == schedules_stops_df['exp_delay_prev_stop'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f63820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values with 0 (first stop)\n",
    "schedules_stops_df['exp_delay_prev_stop'] = schedules_stops_df['exp_delay_prev_stop'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GeoDataFrames for previous and current stop\n",
    "sch_gdf1 = gpd.GeoDataFrame(\n",
    "  schedules_stops_df[['prev_lon', 'prev_lat']],\n",
    "  geometry=gpd.points_from_xy(schedules_stops_df['prev_lon'], schedules_stops_df['prev_lat']),\n",
    "  crs='EPSG:4326' # WGS84 (sea level)\n",
    ").to_crs(epsg=3857) # Convert to metric\n",
    "\n",
    "sch_gdf2 = gpd.GeoDataFrame(\n",
    "  schedules_stops_df[['stop_lon', 'stop_lat']],\n",
    "  geometry=gpd.points_from_xy(schedules_stops_df['stop_lon'], schedules_stops_df['stop_lat']),\n",
    "  crs='EPSG:4326'\n",
    ").to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b93e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distance from previous stop\n",
    "schedules_stops_df['stop_distance'] = sch_gdf1.distance(sch_gdf2)\n",
    "schedules_stops_df['stop_distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd75d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null distances by zero (first stop of the trip)\n",
    "schedules_stops_df['stop_distance'] = schedules_stops_df['stop_distance'].fillna(0)\n",
    "assert schedules_stops_df['stop_distance'].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2069b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stop with largest distance\n",
    "schedules_stops_df.iloc[schedules_stops_df['stop_distance'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5e5b5a",
   "metadata": {},
   "source": [
    "The large distance make sense because the expected time between the the previous stop and this one is 21 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e861489",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedules_stops_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aac6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded columns\n",
    "schedules_stops_df = schedules_stops_df.drop([\n",
    "  'prev_lat',\n",
    "  'prev_lon',\n",
    "  'prev_time',\n",
    "  'today',\n",
    "  'parsed_prev_time',\n",
    "  'trip_start', \n",
    "  'trip_end',\n",
    "  ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66bea68",
   "metadata": {},
   "source": [
    "### Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92861b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep relevant columns\n",
    "trips_df = trips_df[['trip_id', 'route_id', 'trip_headsign', 'wheelchair_accessible']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14997772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename trip_headsign\n",
    "trips_df = trips_df.rename(columns={'trip_headsign': 'route_direction'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate directions\n",
    "condition_list = [\n",
    "\ttrips_df['route_direction'].str.contains('Nord'),\n",
    "\ttrips_df['route_direction'].str.contains('Sud'),\n",
    "  \ttrips_df['route_direction'].str.contains('Ouest'),\n",
    "  \ttrips_df['route_direction'].str.contains('Est'),\n",
    "]\n",
    "label_list = ['North', 'South', 'West', 'East']\n",
    "\n",
    "trips_df['route_direction'] = np.select(condition_list, label_list, default='Metro')\t\n",
    "trips_df['route_direction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892dead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e064c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedules_stops_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with schedules and stops\n",
    "scheduled_trips_df = pd.merge(left=schedules_stops_df, right=trips_df, how='inner', on='trip_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate frequency of arrival per route per stop (keep parsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be4c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduled_trips_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e822aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows where wheelchair_boarding and wheelchair_accessible are different\n",
    "scheduled_trips_df[scheduled_trips_df['wheelchair_boarding'] != scheduled_trips_df['wheelchair_accessible']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep wheelchair_boarding as it's stop specific\n",
    "scheduled_trips_df = scheduled_trips_df.drop('wheelchair_accessible', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab97d0d",
   "metadata": {},
   "source": [
    "### Realtime and Scheduled Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ab184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert route_id to integer\n",
    "trip_updates_df['route_id'] = trip_updates_df['route_id'].str.extract(r'(\\d+)')\n",
    "trip_updates_df['route_id'] = trip_updates_df['route_id'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737976cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proportion of duplicates\n",
    "subset = trip_updates_df.drop('current_time', axis=1).columns\n",
    "duplicate_mask = trip_updates_df.duplicated(subset=subset)\n",
    "print(f'{duplicate_mask.mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7805dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "trip_updates_df = trip_updates_df.drop_duplicates(subset=subset, keep='last').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c783bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename arrival and departure time\n",
    "trip_updates_df = trip_updates_df.rename(columns={'arrival_time': 'rt_arrival_time','departure_time': 'rt_departure_time'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b0d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge trip updates with schedule\n",
    "merged_stm_df = pd.merge(left=trip_updates_df, right=scheduled_trips_df, how='inner', on=['trip_id', 'route_id', 'stop_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3231d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_stm_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41ffdd",
   "metadata": {},
   "source": [
    "#### Calculate Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e78e8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert start_date to datetime\n",
    "merged_stm_df['start_date_dt'] = pd.to_datetime(merged_stm_df['start_date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd061e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse GTFS scheduled arrival and departure times\n",
    "parsed_arrival_time = parse_gtfs_time(merged_stm_df, 'start_date_dt', 'arrival_time')\n",
    "parsed_departure_time = parse_gtfs_time(merged_stm_df, 'start_date_dt', 'departure_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scheduled arrival and departure time to UTC datetime\n",
    "merged_stm_df['sch_arrival_time'] = parsed_arrival_time.dt.tz_convert(timezone.utc)\n",
    "merged_stm_df['sch_departure_time'] = parsed_departure_time.dt.tz_convert(timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rows where scheduled arrival and departure time are different\n",
    "merged_stm_df[merged_stm_df['sch_arrival_time'] != merged_stm_df['sch_departure_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce3671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 0 timestamps with NaN\n",
    "merged_stm_df['rt_arrival_time'] = merged_stm_df['rt_arrival_time'].replace({0: np.nan})\n",
    "merged_stm_df['rt_departure_time'] = merged_stm_df['rt_departure_time'].replace({0: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9960bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert realtime arrival and departure time to UTC datetime\n",
    "merged_stm_df['rt_arrival_time'] = pd.to_datetime(merged_stm_df['rt_arrival_time'], origin='unix', unit='s', utc=True)\n",
    "merged_stm_df['rt_departure_time'] = pd.to_datetime(merged_stm_df['rt_departure_time'], origin='unix', unit='s', utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019218a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate delay (realtime - scheduled)\n",
    "# Start with arrival time, if null, calculate with departure time\n",
    "merged_stm_df['delay'] = (merged_stm_df['rt_arrival_time'] - merged_stm_df['sch_arrival_time']) / pd.Timedelta(seconds=1)\n",
    "merged_stm_df['delay'] = merged_stm_df['delay'].fillna(((merged_stm_df['rt_departure_time'] - merged_stm_df['sch_departure_time']) / pd.Timedelta(seconds=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b5a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distribution\n",
    "merged_stm_df['delay'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584cccf4",
   "metadata": {},
   "source": [
    "#### Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eebfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(merged_stm_df['delay'], bins=50, kde=True)\n",
    "plt.title('Distribution of Delay Times')\n",
    "plt.xlabel('Delay Time (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('../images/delay_histogram.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271e1d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot boxplot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=merged_stm_df['delay'])\n",
    "plt.title('Boxplot of Delay Times (in seconds)')\n",
    "plt.savefig('../images/delay_boxplot.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0764ec",
   "metadata": {},
   "source": [
    "The distribution of delay times is highly skewed, with most values concentrated near 0, but extending both negatively and positively in a wide range. There are extreme outliers stretching up to 55000 seconds (more than 15 hours) and also negative values going beyond -10000 seconds (almost 3 hours). Such extreme values are unrealistic for transit delays. It's very likely they represent data entry errors, sensor glitches or edge cases (canceled trips, detours, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812caa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_stm_df['delay'].max() / merged_stm_df['delay'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e01d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter outliers, based on expected trip duration and \"skewness\" (positive delay is about 4x negative delay)\n",
    "# If a delay is longer than the expected trip duration, it's most likely a cancelled trip.\n",
    "outlier_mask = (merged_stm_df['delay'] <= merged_stm_df['exp_trip_duration'] * -0.25) | (merged_stm_df['delay'] >= merged_stm_df['exp_trip_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect outliers\n",
    "outliers_df = merged_stm_df[outlier_mask]\n",
    "outliers_df[['trip_id', 'route_id', 'stop_name', 'route_direction', 'trip_progress', 'sch_arrival_time', 'delay']].sort_values('delay', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate proportion\n",
    "print(f'{outlier_mask.mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b806778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "merged_stm_df = merged_stm_df[~outlier_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b684f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replot histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(merged_stm_df['delay'], bins=50, kde=True)\n",
    "plt.title('Distribution of Delay Times (After Filtering)')\n",
    "plt.xlabel('Delay Time (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('../images/delay_histogram_filtered.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a103883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replot boxplot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x=merged_stm_df['delay'])\n",
    "plt.title('Boxplot of Delay Times (After Filtering)')\n",
    "plt.savefig('../images/delay_boxplot_filtered.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854cee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get null delays count\n",
    "print(merged_stm_df['delay'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the null delays with the overall average delay\n",
    "merged_stm_df['delay'] = merged_stm_df['delay'].fillna(merged_stm_df['delay'].mean())\n",
    "assert merged_stm_df['delay'].isna().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38a9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new distribution\n",
    "merged_stm_df['delay'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e1b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_stm_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749afa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove uneeded columns\n",
    "merged_stm_df = merged_stm_df.drop(['current_time', 'start_date', 'arrival_time', 'departure_time', 'start_date_dt'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a333d86",
   "metadata": {},
   "source": [
    "### Route Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f43a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "stm_df = pd.merge(left=merged_stm_df, right=routes_df, how='inner', on='route_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd6fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stm_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b431a68",
   "metadata": {},
   "source": [
    "### STM and Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e5b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f9e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert time string to datetime\n",
    "time_dt = pd.to_datetime(weather_df['time'], utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round arrival time to the nearest hour\n",
    "rounded_arrival_dt = stm_df['sch_arrival_time'].dt.round('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format time to match weather data\n",
    "stm_df['time'] = rounded_arrival_dt.dt.strftime('%Y-%m-%dT%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2552f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge STM with weather\n",
    "df = pd.merge(left=stm_df, right=weather_df, how='inner', on='time').drop('time', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54983bb1",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7384a3a4",
   "metadata": {},
   "source": [
    "### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8831e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with constant values or with more than 50% missing values\n",
    "df = df.loc[:, (df.nunique() > 1) & (df.isna().mean() < 0.5)]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d203b",
   "metadata": {},
   "source": [
    "### Convert columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ed74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns with two values\n",
    "two_values = df.loc[:, df.nunique() == 2]\n",
    "for column in two_values.columns:\n",
    "  print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert wheelchair_boarding to boolean\n",
    "df['wheelchair_boarding'] = (df['wheelchair_boarding'] == 1).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5394b58e",
   "metadata": {},
   "source": [
    "### Convert schedule_relationship and occupancy_status to Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categories(df:pd.DataFrame, column:str, map_dict:dict) -> pd.Series:\n",
    "\tcodes = df[column].sort_values().unique()\n",
    "\tcondition_list = []\n",
    "\tlabel_list = []\n",
    "\t\t\n",
    "\tfor code in codes:\n",
    "\t\tcondition_list.append(df[column] == code)\n",
    "\t\tlabel_list.append(map_dict[code])\n",
    "\t\n",
    "\tdf[column] = np.select(condition_list, label_list, default='Unknown')\n",
    "\treturn df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53084d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['schedule_relationship'] = convert_to_categories(df, 'schedule_relationship', SCHEDULE_RELATIONSHIP)\n",
    "df['schedule_relationship'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf5b062",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e89b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d0bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get correlation of delay with other numeric variables\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "corr_matrix = numeric_df.corr()\n",
    "corr_with_delay = corr_matrix.drop('delay', axis=1).loc['delay'].sort_values(key=abs, ascending=False)\n",
    "corr_with_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb537d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV\n",
    "df.to_parquet('../data/stm_weather_merged.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b33a1a",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
