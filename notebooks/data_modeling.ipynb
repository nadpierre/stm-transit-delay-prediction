{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6efc2fa1",
   "metadata": {},
   "source": [
    "# STM Transit Delay Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48c78c",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4739c1",
   "metadata": {},
   "source": [
    "This notebook explores tree-based machine learning models in order to find the one that predicts STM transit delays with the best accuracy. The featured models are XGBoost, LightGBM and CatBoost, because they are more suitable for large datasets with mixed data and high cardinality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec250c6",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f649494",
   "metadata": {},
   "source": [
    "`exp_trip_duration`: Expected duration of a trip, in seconds.<br>\n",
    "`route_direction_North`, `route_direction_South`, `route_direction_West`: Route direction in degrees.<br>\n",
    "`route_type_Night`, `route_type_HighFrequency` : One-Hot features for types of bus lines<br>\n",
    "`frequency_frequent`, `frequency_normal`, `frequency_rare`, `frequency_very_frequent`, `frequency_very_rare`: One-Hot features for number of arrivals per hour.<br>\n",
    "`stop_location_group`: Stop cluster based on coordinates.<br>\n",
    "`stop_distance`: Distance between the previous and current stop, in meters.<br>\n",
    "`trip_phase_middle`, `trip_phase_end`: One-Hot feature for trip progress.<br>\n",
    "`exp_delay_prev_stop`: Expected duration between the previous and current stop, in seconds.<br>\n",
    "`wheelchair_boarding`: Indicates if the stop is accessible for people in wheelchair.<br>\n",
    "`sch_rel_Scheduled`: One-Hot feature for schedule relationship.<br>\n",
    "`time_of_day_evening`, `time_of_day_morning`, `time_of_day_night`: One-Hot features for time of day.<br>\n",
    "`is_peak_hour`: Boolean value indicating if the sheduled arrival time is at peak hour.<br>\n",
    "`temperature_2m`: Air temperature at 2 meters above ground, in Celsius.<br>\n",
    "`relative_humidity_2m`: Relative humidity at 2 meters above ground, in percentage.<br>\n",
    "`precipitation`: Total precipitation (rain, showers, snow) sum of the preceding hour, in millimeters.<br>\n",
    "`pressure_msl`: Atmospheric air pressure reduced to mean sea level (msl), in hPa.<br>\n",
    "`cloud_cover`: Total cloud cover as an area fraction.<br>\n",
    "`windspeed_10m`: Wind speed at 10 meters above ground, in kilometers per hour.<br>\n",
    "`wind_direction_10m`: Wind direction at 10 meters above ground.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d218f9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dded95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d19b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_parquet('../data/preprocessed.parquet')\n",
    "print(f'Shape of dataset: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc11b74",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51490206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from target variable\n",
    "X = df.drop('delay', axis=1)\n",
    "y = df['delay']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e4a098",
   "metadata": {},
   "source": [
    "The 3 models can run multiple iterations with a training and validation set. Therefore, a hold-out set will be kept for the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation-test split (60-20-20)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "del X_temp\n",
    "del y_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f9998",
   "metadata": {},
   "source": [
    "**Scaling**\n",
    "\n",
    "Since only tree-based models are explored in this project, scaling is not needed because the models are not sensitive to the absolute scale or distribution of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a69b3",
   "metadata": {},
   "source": [
    "## Fit Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce7b6b",
   "metadata": {},
   "source": [
    "All models allow to setup a number of rounds and early stopping. To start, all models will run 100 rounds with an early stopping of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96f66c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to track metrics\n",
    "reg_metrics_df = pd.DataFrame(columns=['model', 'MAE', 'RMSE', 'R²'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reg_metrics(reg_metrics_df:pd.DataFrame, y_pred:pd.Series, y_true:pd.Series, model_name:str) -> pd.DataFrame:\n",
    "\tmae = mean_absolute_error(y_true, y_pred)\n",
    "\trmse = root_mean_squared_error(y_true, y_pred)\n",
    "\tr2 = r2_score(y_true, y_pred)\n",
    "\n",
    "\treg_metrics_df.loc[len(reg_metrics_df)] = [model_name, mae, rmse, r2]\n",
    "\treturn reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3f3056",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression matrices\n",
    "xg_train_data = xgb.DMatrix(X_train, y_train, enable_categorical=False)\n",
    "xg_val_data = xgb.DMatrix(X_val, y_val, enable_categorical=False)\n",
    "xg_test_data = xgb.DMatrix(X_test, y_test, enable_categorical=False)\n",
    "xg_eval_set = [(xg_train_data, 'train'), (xg_val_data, 'validation')]\n",
    "xg_test_set = [(xg_train_data, 'train'), (xg_test_data, 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303fcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "xg_reg_base = xgb.train(\n",
    "  params= {'objective': 'reg:squarederror', 'tree_method': 'hist'},\n",
    "  dtrain=xg_train_data,\n",
    "  num_boost_round=100,\n",
    "  evals=xg_eval_set,\n",
    "  verbose_eval=10,\n",
    "  early_stopping_rounds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = xg_reg_base.predict(xg_val_data)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_val, 'xg_reg_base')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0a5e7",
   "metadata": {},
   "source": [
    "**MAE**<br>\n",
    "On average, the predictions are off by 74 seconds, which is not very good.\n",
    "\n",
    "**RMSE**<br>\n",
    "The higher RMSE compared to MAE suggests that there are some significant prediction errors that influence the overall error metric.\n",
    "\n",
    "**R²**<br>\n",
    "The model explains 22% of the variance, which is not good but understandable because of how random transit delays can be (bad weather, vehicle breakdown, accidents, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960dd759",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3edbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression matrices\n",
    "lgb_train_data = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_val_data = lgb.Dataset(X_val, label=y_val, reference=lgb_train_data)\n",
    "lgb_test_data = lgb.Dataset(X_test, label=y_test, reference=lgb_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32750cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lgb_reg_base = lgb.train(\n",
    "    params={\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': -1\n",
    "    },\n",
    "    train_set=lgb_train_data,\n",
    "    valid_sets=[lgb_val_data],\n",
    "    num_boost_round=100,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = lgb_reg_base.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_val, 'lgb_reg_base')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2f15c1",
   "metadata": {},
   "source": [
    "Overall, the LightGBM model performs worse than XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a61f6b",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b34ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "cat_reg_base = CatBoostRegressor(\n",
    "    iterations=100,\n",
    "    learning_rate=0.05,\n",
    "    depth=10,\n",
    "    random_seed=42,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "cat_reg_base.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = cat_reg_base.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_val, 'cat_reg_base')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e751ec",
   "metadata": {},
   "source": [
    "CatBoost performs almost like LightGBM. Without tuning, XGBoost seems to capture a bit more of the underlying patterns than the two other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4284c",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd661f2f",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40747e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 600],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2682ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "xg_best_model = random_search.best_estimator_\n",
    "xg_best_params = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c527b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model with more boost rounds\n",
    "xg_reg_tuned = xgb.train(\n",
    "  params= {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'hist',\n",
    "    'max_depth': xg_best_params['max_depth'],\n",
    "    'learning_rate': xg_best_params['learning_rate'],\n",
    "    'subsample': xg_best_params['subsample'],\n",
    "    'colsample_bytree': xg_best_params['colsample_bytree'],\n",
    "  },\n",
    "  dtrain=xg_train_data,\n",
    "  num_boost_round=10000,\n",
    "  evals=xg_eval_set,\n",
    "  verbose_eval=50,\n",
    "  early_stopping_rounds=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ca1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = xg_reg_tuned.predict(xg_val_data)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_val, 'xg_reg_tuned')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b84a0",
   "metadata": {},
   "source": [
    "There's a significant improvement from the base XGBoost model and it's the best performing model so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688cf44e",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "  'n_estimators': [100, 500, 1000],\n",
    "  'learning_rate': [0.01, 0.05, 0.1],\n",
    "  'max_depth': [5, 10, 15],\n",
    "  'num_leaves': [20, 31, 40],\n",
    "  'min_child_samples': [10, 20, 30],\n",
    "  'subsample': [0.8, 1.0],\n",
    "  'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=2, \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "lgb_best_model = random_search.best_estimator_\n",
    "lgb_best_params = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with more boost rounds and early stopping\n",
    "lgb_reg_tuned = lgb.train(\n",
    "    params={\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'n_estimators': lgb_best_params['n_estimators'],\n",
    "        'learning_rate': lgb_best_params['learning_rate'],\n",
    "        'max_depth': lgb_best_params['max_depth'],\n",
    "        'num_leaves': lgb_best_params['num_leaves'],\n",
    "        'min_child_samples': lgb_best_params['min_child_samples'],\n",
    "        'subsample': lgb_best_params['subsample'],\n",
    "        'colsample_bytree': lgb_best_params['colsample_bytree']\n",
    "    },\n",
    "    train_set=lgb_train_data,\n",
    "    valid_sets=[lgb_val_data],\n",
    "    num_boost_round=10000,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = lgb_reg_tuned.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_val, 'lgb_reg_tuned')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf4eee",
   "metadata": {},
   "source": [
    "The performance is very similar to the previous tuned model. The MAE is slightly worse but the RMSE and the R-sqared are slightly better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8d5086",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {\n",
    "  'iterations': [100, 500, 1000],\n",
    "  'learning_rate': [0.01, 0.05, 0.1],\n",
    "  'depth': [6, 8, 10],\n",
    "  'l2_leaf_reg': [1, 3, 5],\n",
    "  'border_count': [32, 64, 128],\n",
    "  'bagging_temperature': [0, 1, 5],\n",
    "}\n",
    "\n",
    "cat_model = CatBoostRegressor(verbose=0, random_seed=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=cat_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=2,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "cat_best_model = random_search.best_estimator_\n",
    "cat_best_params = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model with more iterations\n",
    "cat_reg_tuned = CatBoostRegressor(\n",
    "    iterations=10000,\n",
    "    learning_rate=cat_best_params['learning_rate'],\n",
    "    depth=cat_best_params['depth'],\n",
    "    l2_leaf_reg=cat_best_params['l2_leaf_reg'],\n",
    "    border_count=cat_best_params['border_count'],\n",
    "    bagging_temperature=cat_best_params['bagging_temperature'],\n",
    "    random_seed=42,\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "cat_reg_tuned.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e0b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = cat_reg_tuned.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_val, 'cat_reg_tuned')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a90fcf",
   "metadata": {},
   "source": [
    "CatBoost is the best performing model so far. This is the model that will be used for the rest of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cebbac9",
   "metadata": {},
   "source": [
    "## Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0854867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "best_model = cat_reg_tuned\n",
    "y_pred = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180dd0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15, 7))\n",
    "\n",
    "# Predicted vs. actual values\n",
    "ax1.scatter(x=y_pred, y=y_val)\n",
    "ax1.set_title('Predicted vs. Actual values')\n",
    "ax1.set_xlabel('Predicted delay (seconds)')\n",
    "ax1.set_ylabel('Actual delay (seconds)')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Residuals\n",
    "residuals = y_val - y_pred\n",
    "ax2.scatter(x=y_pred, y=residuals)\n",
    "ax2.set_title('Residual Plot')\n",
    "ax2.set_xlabel('Predicted Delay (seconds)')\n",
    "ax2.set_ylabel('Residuals (seconds)')\n",
    "ax2.axhline(0, linestyle='--', color='orange')\n",
    "ax2.grid(True)\n",
    "\n",
    "fig.suptitle('Residual Analysis', fontsize=18)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'../images/residual_analysis.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52270f20",
   "metadata": {},
   "source": [
    "**Predicted vs. Actual Plot**\n",
    "\n",
    "There's a dense cluster around 0 for both predicted and actual values, indicating many predictions and centered near 0. However, there is substantial spread both above and below the diagonal line, which suggests underprediction and overprediction. There are clear outliers that are far from the main cluster.\n",
    "\n",
    "\n",
    "**Residual Plot**\n",
    "\n",
    "The residuals show a visible diagonal stripe pattern, which indicates a systematic error in prediction. The spread of residuals increases as the predicted delay increases. This is a sign of heteroscedasticity (the variance of errors is not constant across all predictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5448a",
   "metadata": {},
   "source": [
    "## Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = best_model.get_feature_importance(prettified=True)\n",
    "feature_importances = feature_importances.sort_values(by='Importances', ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da54f573",
   "metadata": {},
   "source": [
    "## SHAP Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac48272",
   "metadata": {},
   "source": [
    "## Feature Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec1d96",
   "metadata": {},
   "source": [
    "## Retrain Model with Best Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f2a87",
   "metadata": {},
   "source": [
    "## Retune Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97a0186",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ac4ed",
   "metadata": {},
   "source": [
    "### Evaluate with Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e5c92",
   "metadata": {},
   "source": [
    "### Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model\n",
    "joblib.dump(best_model, 'best_xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e39b53",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
