{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6efc2fa1",
   "metadata": {},
   "source": [
    "# STM Transit Delay Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca48c78c",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4739c1",
   "metadata": {},
   "source": [
    "This notebook explores tree-based regression and classification models in order to find the one that predicts STM transit delays with the best accuracy. The featured models are XGBoost, LightGBM and CatBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec250c6",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f649494",
   "metadata": {},
   "source": [
    "`exp_trip_duration`: Expected duration of a trip, in seconds.<br>\n",
    "`route_direction`: Route direction in degrees.<br>\n",
    "`route_type_Night`, `route_type_High Frequency` : One-Hot features for types of bus lines<br>\n",
    "`stop_location_group`: Stop cluster based on coordinates.<br>\n",
    "`stop_distance`: Distance between the previous and current stop, in meters.<br>\n",
    "`trip_phase_end`: One-Hot feature for trip progress.<br>\n",
    "`exp_delay_prev_stop`: Expected duration between the previous and current stop, in seconds.<br>\n",
    "`wheelchair_boarding`: Indicates if the stop is accessible for people in wheelchair.<br>\n",
    "`sch_rel_Scheduled`: One-Hot feature for schedule relationship.<br>\n",
    "`time_of_day_evening`, `time_of_day_morning`, `time_of_day_night`: One-Hot features for time of day.<br>\n",
    "`is_weekend`: Boolean value if the day of week in on the weekend.<br>\n",
    "`is_peak_hour`: Boolean value indicating if the sheduled arrival time is at peak hour.<br>\n",
    "`temperature`: Air temperature at 2 meters above ground, in Celsius.<br>\n",
    "`relative_humidity`: Relative humidity at 2 meters above ground, in percentage.<br>\n",
    "`precipitation`: Total precipitation (rain, showers, snow) sum of the preceding hour, in millimeters.<br>\n",
    "`pressure`: Atmospheric air pressure reduced to mean sea level (msl), in hPa.<br>\n",
    "`cloud_cover`: Total cloud cover as an area fraction.<br>\n",
    "`windspeed`: Wind speed at 10 meters above ground, in kilometers per hour.<br>\n",
    "`wind_direction`: Wind direction at 10 meters above ground.<br>\n",
    "`delay`: Difference between real and scheduled arrival time, in seconds.<br>\n",
    "`delay_class`: Delay category, from early to late."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d218f9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2dded95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, f1_score, classification_report, mean_absolute_error, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "import sys\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa6a5db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom code\n",
    "sys.path.insert(0, '..')\n",
    "from scripts.custom_functions import DELAY_CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d19b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (7523993, 22)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('../data/preprocessed.parquet')\n",
    "print(f'Shape of dataset: {df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc11b74",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2112ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the large volume of data, use 60% for training\n",
    "df_train, df_temp = train_test_split(\n",
    "    df, \n",
    "    test_size=0.4, \n",
    "    stratify=df['delay_class'], # stratify with delay class\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09c43b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split validation and test sets\n",
    "df_val, df_test = train_test_split(\n",
    "  df_temp,\n",
    "  test_size=0.5,\n",
    "  stratify=df_temp['delay_class'],\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "del df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9271c85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delay_class\n",
      "1    0.884209\n",
      "2    0.107581\n",
      "0    0.008210\n",
      "Name: proportion, dtype: float64\n",
      "delay_class\n",
      "1    0.884209\n",
      "2    0.107581\n",
      "0    0.008210\n",
      "Name: proportion, dtype: float64\n",
      "delay_class\n",
      "1    0.884209\n",
      "2    0.107581\n",
      "0    0.008210\n",
      "Name: proportion, dtype: float64\n",
      "delay_class\n",
      "1    0.884209\n",
      "2    0.107580\n",
      "0    0.008210\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check if the delay class distribution is preserved\n",
    "print(df['delay_class'].value_counts(normalize=True))\n",
    "print(df_train['delay_class'].value_counts(normalize=True))\n",
    "print(df_val['delay_class'].value_counts(normalize=True))\n",
    "print(df_test['delay_class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42ca52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from target variables\n",
    "feature_cols = [col for col in df.columns if col not in ['delay', 'delay_class']]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "X_val = df_val[feature_cols]\n",
    "X_test = df_test[feature_cols]\n",
    "\n",
    "y_reg_train = df_train['delay']\n",
    "y_reg_val = df_val['delay']\n",
    "y_reg_test = df_test['delay']\n",
    "\n",
    "y_class_train = df_train['delay_class']\n",
    "y_class_val = df_val['delay_class']\n",
    "y_class_test = df_test['delay_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f9998",
   "metadata": {},
   "source": [
    "**Scaling**\n",
    "\n",
    "Since only tree-based models are explored in this project, scaling is not needed because the models are not sensitive to the absolute scale or distribution of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08eb157",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a69b3",
   "metadata": {},
   "source": [
    "### Fit Base Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce7b6b",
   "metadata": {},
   "source": [
    "All models allow to setup a number of rounds and early stopping. To start, all models will run 100 rounds with an early stopping of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f96f66c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to track metrics\n",
    "reg_metrics_df = pd.DataFrame(columns=['model', 'MAE', 'RMSE', 'R²'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a14b6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reg_metrics(reg_metrics_df:pd.DataFrame, y_pred:pd.Series, y_val:pd.Series, model_name:str) -> pd.DataFrame:\n",
    "\tmae = mean_absolute_error(y_val, y_pred)\n",
    "\trmse = root_mean_squared_error(y_val, y_pred)\n",
    "\tr2 = r2_score(y_val, y_pred)\n",
    "\n",
    "\treg_metrics_df.loc[len(reg_metrics_df)] = [model_name, mae, rmse, r2]\n",
    "\treturn reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3f3056",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e10d4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression matrices\n",
    "xg_train_data = xgb.DMatrix(X_train, y_reg_train, enable_categorical=False)\n",
    "xg_val_data = xgb.DMatrix(X_val, y_reg_val, enable_categorical=False)\n",
    "xg_eval_set = [(xg_train_data, 'train'), (xg_val_data, 'validation')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8303fcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:152.42343\tvalidation-rmse:152.79920\n",
      "[10]\ttrain-rmse:149.66869\tvalidation-rmse:150.04058\n",
      "[20]\ttrain-rmse:148.86776\tvalidation-rmse:149.26858\n",
      "[30]\ttrain-rmse:148.22290\tvalidation-rmse:148.63382\n",
      "[40]\ttrain-rmse:147.69113\tvalidation-rmse:148.14166\n",
      "[50]\ttrain-rmse:147.26310\tvalidation-rmse:147.73195\n",
      "[60]\ttrain-rmse:146.87950\tvalidation-rmse:147.36623\n",
      "[70]\ttrain-rmse:146.48733\tvalidation-rmse:146.99572\n",
      "[80]\ttrain-rmse:146.25509\tvalidation-rmse:146.78115\n",
      "[90]\ttrain-rmse:145.90587\tvalidation-rmse:146.45284\n",
      "[99]\ttrain-rmse:145.62521\tvalidation-rmse:146.19715\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "xg_reg_base = xgb.train(\n",
    "  params= {'objective': 'reg:squarederror', 'tree_method': 'hist'},\n",
    "  dtrain=xg_train_data,\n",
    "  num_boost_round=100,\n",
    "  evals=xg_eval_set,\n",
    "  verbose_eval=10,\n",
    "  early_stopping_rounds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "550d1211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "R²",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "045bfbd2-4ee5-460d-bd7b-fb2033280430",
       "rows": [
        [
         "0",
         "xg_reg_base",
         "78.73097133963482",
         "146.19714864255482",
         "0.09850987066336114"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xg_reg_base</td>\n",
       "      <td>78.730971</td>\n",
       "      <td>146.197149</td>\n",
       "      <td>0.09851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model        MAE        RMSE       R²\n",
       "0  xg_reg_base  78.730971  146.197149  0.09851"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "y_pred = xg_reg_base.predict(xg_val_data)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'xg_reg_base')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0a5e7",
   "metadata": {},
   "source": [
    "**MAE**<br>\n",
    "On average, the predictions are off by 79 seconds, which is not very good.\n",
    "\n",
    "**RMSE**<br>\n",
    "The higher RMSE compared to MAE suggests that there are some significant prediction errors that influence the overall error metric.\n",
    "\n",
    "**R²**<br>\n",
    "The model explains 9.85% of the variance, which indicates the model is a poor fit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960dd759",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32750cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "lgb_train_data = lgb.Dataset(X_train, label=y_reg_train)\n",
    "lgb_val_data = lgb.Dataset(X_val, label=y_reg_val, reference=lgb_train_data)\n",
    "\n",
    "lgb_reg_base = lgb.train(\n",
    "    {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': -1\n",
    "    },\n",
    "    lgb_train_data,\n",
    "    valid_sets=[lgb_val_data],\n",
    "    num_boost_round=100,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = lgb_reg_base.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'lgb_reg_base')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2f15c1",
   "metadata": {},
   "source": [
    "Overall, the LightGBM model performs worse than XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a61f6b",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b34ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "cat_reg_base = CatBoostRegressor(\n",
    "    iterations=100,\n",
    "    learning_rate=0.05,\n",
    "    depth=10,\n",
    "    random_seed=42,\n",
    "    verbose=10\n",
    ")\n",
    "\n",
    "cat_reg_base.fit(X_train, y_reg_train, eval_set=(X_val, y_reg_val), early_stopping_rounds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = cat_reg_base.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'cat_reg_base')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e751ec",
   "metadata": {},
   "source": [
    "CatBoost performs slighly better than LightGBM but worse than XGBoost. Without hyperparameter tuning, XGBoost seems to capture a bit more of the underlying patterns than the two other models, but it's still a poor fit for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4284c",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6141b20",
   "metadata": {},
   "source": [
    "Because of the large volume of data, a randomized search will be performed for each model instead of a grid search, wihout K-Fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd661f2f",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40747e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_options = list(range(100, 700, 100))\n",
    "max_depth_options = [3, 5, 7]\n",
    "learning_rate_options = [0.01, 0.1, 0.2]\n",
    "subsample_options = [0.6, 0.8, 1.0]\n",
    "colsample_bytree_options = [0.6, 0.8, 1.0]\n",
    "\n",
    "best_model = None\n",
    "best_params = {}\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for i in range(1, 21): # 20 combinations\n",
    "  params = {\n",
    "    'n_estimators': random.choice(n_estimators_options),\n",
    "    'max_depth': random.choice(max_depth_options),\n",
    "    'learning_rate': random.choice(learning_rate_options),\n",
    "    'subsample': random.choice(subsample_options),\n",
    "    'colsample_bytree': random.choice(colsample_bytree_options)\n",
    "  }\n",
    "\n",
    "  print(f'Combination #{i}: {params}')\n",
    "\n",
    "  xgb_model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=params['n_estimators'],\n",
    "    max_depth=params['max_depth'],\n",
    "    learning_rate=params['learning_rate'],\n",
    "    subsample=params['subsample'],\n",
    "    colsample_bytree=params['colsample_bytree'],\n",
    "    random_state=42)\n",
    "  \n",
    "  xgb_model.fit(X_train, y_reg_train)\n",
    "\n",
    "  y_pred = xgb_model.predict(X_val)\n",
    "  rmse = root_mean_squared_error(y_reg_val, y_pred)\n",
    "  print(f'RMSE: {rmse}\\n')\n",
    "\n",
    "  if rmse < best_rmse:\n",
    "    best_model = xgb_model\n",
    "    best_params = params\n",
    "    best_rmse = rmse\n",
    "\n",
    "if best_model != None:\n",
    "  print(f'Best RMSE: {best_rmse}')\n",
    "  print(f'Best parameters: {best_params}')\n",
    "else:\n",
    "  print('No better model was found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c527b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model with more boost rounds\n",
    "xg_best_params = best_params\n",
    "\n",
    "xg_reg_tuned = xgb.train(\n",
    "  params= {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'hist',\n",
    "    'n_estimators': xg_best_params['n_estimators'],\n",
    "    'max_depth': xg_best_params['max_depth'],\n",
    "    'learning_rate': xg_best_params['learning_rate'],\n",
    "    'subsample': xg_best_params['subsample'],\n",
    "    'colsample_bytree': xg_best_params['colsample_bytree'],\n",
    "  },\n",
    "  dtrain=xg_train_data,\n",
    "  num_boost_round=1000,\n",
    "  evals=evals,\n",
    "  verbose_eval=10,\n",
    "  early_stopping_rounds=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ca1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = xg_reg_tuned.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'xg_reg_tuned')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130b84a0",
   "metadata": {},
   "source": [
    "There's a significant improvement from the base XGBoost model, especially the R-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688cf44e",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_options = list(range(100, 1100, 100))\n",
    "learning_rate_options = [0.01, 0.05, 0.1]\n",
    "max_depth_options = [5, 10, 15]\n",
    "num_leaves_options = [20, 30, 40]\n",
    "min_child_samples_options = [10, 20, 30]\n",
    "subsample_options = [0.8, 1.0]\n",
    "colsample_bytree_options = [0.8, 1.0]\n",
    "\n",
    "best_model = None\n",
    "best_params = {}\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for i in range(1, 21):\n",
    "  params = {\n",
    "    'n_estimators': random.choice(n_estimators_options),\n",
    "    'learning_rate': random.choice(learning_rate_options),\n",
    "    'max_depth': random.choice(max_depth_options),\n",
    "    'num_leaves': random.choice(num_leaves_options),\n",
    "    'min_child_samples': random.choice(min_child_samples_options),\n",
    "    'subsample': random.choice(subsample_options),\n",
    "    'colsample_bytree': random.choice(colsample_bytree_options)\n",
    "  }\n",
    "\n",
    "  print(f'Combination #{i}: {params}')\n",
    "\n",
    "  lgb_model = lgb.LGBMRegressor(\n",
    "    n_estimators=params['n_estimators'],\n",
    "    learning_rate=params['learning_rate'],\n",
    "    max_depth=params['max_depth'],\n",
    "    num_leaves=params['num_leaves'],\n",
    "    min_child_samples=params['min_child_samples'],\n",
    "    subsample=params['subsample'],\n",
    "    colsample_bytree=params['colsample_bytree'],\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=-1)\n",
    "\n",
    "  lgb_model.fit(X_train, y_reg_train)\n",
    "\n",
    "  y_pred = lgb_model.predict(X_val)\n",
    "  rmse = root_mean_squared_error(y_reg_val, y_pred)\n",
    "  print(f'RMSE: {rmse}\\n')\n",
    "\n",
    "  if rmse < best_rmse:\n",
    "    best_model = lgb_model\n",
    "    best_params = params\n",
    "    best_rmse = rmse\n",
    "\n",
    "if best_model != None:\n",
    "  print(f'Best RMSE: {best_rmse}')\n",
    "  print(f'Best parameters: {best_params}')\n",
    "else:\n",
    "  print('No better model was found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with more boost rounds and early stopping\n",
    "lgb_best_params = best_params\n",
    "lgb_reg_tuned = lgb.train(\n",
    "    {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'n_estimators': lgb_best_params['n_estimators'],\n",
    "        'learning_rate': lgb_best_params['learning_rate'],\n",
    "        'max_depth': lgb_best_params['max_depth'],\n",
    "        'num_leaves': lgb_best_params['num_leaves'],\n",
    "        'min_child_samples': lgb_best_params['min_child_samples'],\n",
    "        'subsample': lgb_best_params['subsample'],\n",
    "        'colsample_bytree': lgb_best_params['colsample_bytree']\n",
    "    },\n",
    "    lgb_train_data,\n",
    "    valid_sets=[lgb_val_data],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = lgb_reg_tuned.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'lgb_reg_tuned')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaf4eee",
   "metadata": {},
   "source": [
    "Interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8d5086",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_options = list(range(500, 1100, 100))\n",
    "learning_rate_options = [0.01, 0.05, 0.1]\n",
    "depth_options = [6, 8, 10]\n",
    "l2_leaf_reg_options = [1, 3, 5]\n",
    "border_count_options = [32, 64, 128]\n",
    "bagging_temperature_options = [0, 1, 5]\n",
    "\n",
    "best_model = None\n",
    "best_params = {}\n",
    "best_rmse = float('inf')\n",
    "\n",
    "for i in range(1, 21): # 30 combinations\n",
    "  params = {\n",
    "    'iterations': random.choice(iterations_options),\n",
    "    'learning_rate': random.choice(learning_rate_options),\n",
    "    'depth': random.choice(depth_options) ,\n",
    "    'l2_leaf_reg': random.choice(l2_leaf_reg_options),\n",
    "    'border_count': random.choice(border_count_options),\n",
    "    'bagging_temperature': random.choice(bagging_temperature_options)\n",
    "  }\n",
    "\n",
    "  print(f'Combination #{i}: {params}')\n",
    "\n",
    "  cat_model = CatBoostRegressor(\n",
    "    iterations=params['iterations'],\n",
    "    learning_rate=params['iterations'],\n",
    "    depth=params['depth'],\n",
    "    l2_leaf_reg=params['l2_leaf_reg'],\n",
    "    border_count=params['border_count'],\n",
    "    bagging_temperature=params['bagging_temperature'],\n",
    "    verbose=None,\n",
    "    random_seed=42)\n",
    "\n",
    "  cat_model.fit(X_train, y_reg_train)\n",
    "\n",
    "  y_pred = cat_model.predict(X_val)\n",
    "  rmse = root_mean_squared_error(y_reg_val, y_pred)\n",
    "  print(f'RMSE: {rmse}\\n')\n",
    "\n",
    "  if rmse < best_rmse:\n",
    "    best_model = cat_model\n",
    "    best_params = params\n",
    "    best_rmse = rmse\n",
    "\n",
    "if best_model != None:\n",
    "  print(f'Best RMSE: {best_rmse}')\n",
    "  print(f'Best parameters: {best_params}')\n",
    "else:\n",
    "  print('No better model was found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best model with more iterations\n",
    "cat_best_params = best_params\n",
    "\n",
    "cat_reg_tuned = CatBoostRegressor(\n",
    "    iterations=cat_best_params['iterations'],\n",
    "    learning_rate=cat_best_params['learning_rate'],\n",
    "    depth=cat_best_params['depth'],\n",
    "    l2_leaf_reg=cat_best_params['l2_leaf_reg'],\n",
    "    border_count=cat_best_params['border_count'],\n",
    "    bagging_temperature=cat_best_params['bagging_temperature'],\n",
    "    random_seed=42,\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "cat_reg_tuned.fit(X_train, y_reg_train, eval_set=(X_val, y_reg_val), early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "cat_reg_tuned = best_model\n",
    "cat_best_params = best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e0b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "y_pred = cat_reg_tuned.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'cat_reg_tuned')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2191d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model with lowest RMSE\n",
    "reg_metrics_df.nsmallest(n=1, columns='RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a116e48",
   "metadata": {},
   "source": [
    "The best model is XGBoost. This is the model that will be used for the rest of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cebbac9",
   "metadata": {},
   "source": [
    "### Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f59be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model = xg_reg_tuned\n",
    "y_pred = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180dd0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15, 7))\n",
    "\n",
    "# Predicted vs. actual values\n",
    "ax1.scatter(x=y_pred, y=y_true)\n",
    "ax1.set_title('Predicted vs. Actual values')\n",
    "ax1.set_xlabel('Predicted delay (seconds)')\n",
    "ax1.set_ylabel('Actual delay (seconds)')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Residuals\n",
    "residuals = y_true - y_pred\n",
    "ax2.scatter(x=y_pred, y=residuals)\n",
    "ax2.set_title('Residual Plot')\n",
    "ax2.set_xlabel('Predicted Delay (seconds)')\n",
    "ax2.set_ylabel('Residuals (seconds)')\n",
    "ax2.axhline(0, linestyle='--', color='orange')\n",
    "ax2.grid(True)\n",
    "\n",
    "fig.suptitle('Residual Analysis', fontsize=18)\n",
    "fig.tight_layout()\n",
    "fig.savefig(f'../images/residual_analysis_{model_name}.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5448a",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154baace",
   "metadata": {},
   "source": [
    "#### MDI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da54f573",
   "metadata": {},
   "source": [
    "#### SHAP Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac48272",
   "metadata": {},
   "source": [
    "### Feature Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec1d96",
   "metadata": {},
   "source": [
    "### Retrain Model with Best Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f2a87",
   "metadata": {},
   "source": [
    "### Retune Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fb329",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aca4f26",
   "metadata": {},
   "source": [
    "### Fit Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe to track metrics\n",
    "class_metrics_df = pd.DataFrame(columns=['model', 'params', 'f1_macro', 'kappa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea64443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_class_metrics(class_metrics_df:pd.DataFrame, model, y_pred:pd.Series, y_val:pd.Series, model_name:str) -> pd.DataFrame:\n",
    "\tf1_macro = f1_score(y_val, y_pred, average='macro')\n",
    "\tkappa = cohen_kappa_score(y_val, y_pred)\n",
    "\n",
    "\tclass_metrics_df.loc[len(class_metrics_df)] = [model_name, model.get_params(), f1_macro, kappa]\n",
    "\treturn class_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f516f2ec",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235b416",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00092850",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646de56",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63746edb",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feebc78b",
   "metadata": {},
   "source": [
    "### Feature Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02090dda",
   "metadata": {},
   "source": [
    "### Retrain Model with Best Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7a47d7",
   "metadata": {},
   "source": [
    "### Retune Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97a0186",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ac4ed",
   "metadata": {},
   "source": [
    "### Evaluate with Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e5c92",
   "metadata": {},
   "source": [
    "### Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model\n",
    "joblib.dump(best_model, 'best_xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e39b53",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6e3bf",
   "metadata": {},
   "source": [
    "# STM Transit Delay Data Modeling Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12352da5",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1364f5ed",
   "metadata": {},
   "source": [
    "#### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7456e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit base model\n",
    "rf_reg_base = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_reg_base.fit(X_train_sample, y_reg_train_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a862cd",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a80db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e465996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "y_pred = rf_reg_base.predict(X_val)\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'rf_reg_base')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec75f51",
   "metadata": {},
   "source": [
    "**MAE**<br>\n",
    "On average, the predictions are off by 74 seconds, which is not very good.\n",
    "\n",
    "**RMSE**<br>\n",
    "The higher RMSE compared to MAE suggests that there are some significant prediction errors that influence the overall error metric.\n",
    "\n",
    "**R²**<br>\n",
    "The model explains 10.85% of the variance, which indicates the model is a poor fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb227fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e54f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residual analysis\n",
    "plot_residuals(y_pred, y_reg_val, 'rf_reg_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567963b",
   "metadata": {},
   "source": [
    "Interpret plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459b917",
   "metadata": {},
   "source": [
    "### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbbbe6d",
   "metadata": {},
   "source": [
    "#### Fit Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede95ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2abd212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d562f01",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xg_reg_base.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'xg_reg_base')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0c22b5",
   "metadata": {},
   "source": [
    "**MAE:**\n",
    "\n",
    "This is a slight improvement over the Random Forest model. The model is now, on average, 73.9 seconds off in its predictions, which is a reduction of almost 10 seconds.\n",
    "\n",
    "**RMSE:**\n",
    "\n",
    "The RMSE has also decreased compared to the previous model indicating that the XGBoost model is performing better and has reduced the impact of large errors.\n",
    "\n",
    "**R²:**\n",
    "\n",
    "This is a substantial improvement from -4.67%. With an R-squared of 12.52%, the XGBoost model explains more variance in the data, which shows that it's capturing more of the underlying patterns than the previous model. However, it's still a poor fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96184a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residual analysis\n",
    "plot_residuals(y_pred, y_reg_val, 'xg_reg_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be9955c",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform GridSearch with 5-fold CV\n",
    "xgb = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_reg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "xg_reg_tuned = grid_search.best_estimator_\n",
    "xg_best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9500bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xg_reg_tuned.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'xg_reg_tuned')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc78cb3",
   "metadata": {},
   "source": [
    "### LightGBM Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a23bc2",
   "metadata": {},
   "source": [
    "#### Fit Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e1c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89448efb",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd711686",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_reg_base.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'lgb_reg_base')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f646fbd9",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfe684",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'num_leaves': [20, 31, 40],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "lgb_grid = GridSearchCV(\n",
    "    estimator=lgb_model,\n",
    "    param_grid=lgb_param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgb_grid.fit(X_train, y_reg_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b6361",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg_tuned = lgb_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters and score\n",
    "print(\"Best Parameters for LightGBM:\")\n",
    "print(lgb_grid.best_params_)\n",
    "print(f\"Best RMSE: {-lgb_grid.best_score_ ** 0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d09f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgb_reg_tuned.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'lgb_reg_tuned')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b40ecb",
   "metadata": {},
   "source": [
    "### CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf8f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_reg_base = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=10,\n",
    "    random_seed=42,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "cat_reg_base.fit(X_train, y_reg_train, eval_set=(X_val, y_reg_val), early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cat_reg_base.predict(X_val)\n",
    "\n",
    "reg_metrics_df = add_reg_metrics(reg_metrics_df, y_pred, y_reg_val, 'cat_reg_base')\n",
    "reg_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e160d6",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737fd9d",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b07b964",
   "metadata": {},
   "source": [
    "#### Fit Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987179ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight helps for rare classes\n",
    "rf_class_base = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1) \n",
    "rf_class_base.fit(X_train, y_class_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7ec7b",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798939e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30117252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_class_base.predict(X_val)\n",
    "\n",
    "class_metrics_df = add_class_metrics(class_metrics_df, rf_class_base, y_pred, y_class_val, 'rf_class_base')\n",
    "class_metrics_df[['model', 'f1_macro', 'kappa']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39dc3db",
   "metadata": {},
   "source": [
    "Interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd3da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = DELAY_CLASS.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f55448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_report(y_val, y_pred, labels):\n",
    "\tprint(classification_report(y_val, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b57db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print_class_report(y_class_val, y_pred, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7209c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_val, y_pred, labels:list, model_name:str):\n",
    "\tcm = confusion_matrix(y_val, y_pred)\n",
    "\tplt.figure(figsize=(8, 6))\n",
    "\tsns.heatmap(cm, annot=True, fmt='d', cmap='crest', xticklabels=labels, yticklabels=labels)\n",
    "\tplt.xlabel('Predicted', fontsize=14)\n",
    "\tplt.ylabel('Actual', fontsize=14)\n",
    "\tplt.title('Confusion Matrix', fontsize=18)\n",
    "\tplt.tight_layout()\n",
    "\tplt.savefig(f'../images/cm_{model_name}.png', bbox_inches='tight')\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c49c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix heatmap\n",
    "plot_confusion_matrix(y_class_val, y_pred, class_labels, 'rf_class_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6195873",
   "metadata": {},
   "source": [
    "Interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be4759",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': list(range(100, 700, 100)),\n",
    "    'max_depth': [None, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "# Initialize base model\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Randomized search with 2-fold CV (to save computation time)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10, # 10 combinations\n",
    "    cv=2,\n",
    "    verbose=1,\n",
    "    scoring='f1_macro', # optimize for macro F1\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit search\n",
    "random_search.fit(X_train, y_class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2dd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "rf_class_tuned = random_search.best_estimator_\n",
    "rf_best_params = random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40367168",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_class_tuned.predict(X_val)\n",
    "\n",
    "class_metrics_df = add_class_metrics(class_metrics_df, rf_class_tuned, y_pred, y_class_val, 'rf_class_tuned')\n",
    "class_metrics_df[['model', 'f1_macro', 'kappa']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a6e58",
   "metadata": {},
   "source": [
    "Interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61563844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print_class_report(y_class_val, y_pred, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "plot_confusion_matrix(y_class_val, y_pred, class_labels, 'rf_class_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1809bd67",
   "metadata": {},
   "source": [
    "Interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9c3912",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353f27c",
   "metadata": {},
   "source": [
    "#### Fit Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980d3845",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_class_base = xgb.XGBClassifier(\n",
    "\tobjective='multi:softmax',\n",
    "  \tnum_class=3,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "xg_class_base.fit(X_train, y_class_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb0678b",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c946dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xg_class_base.predict(X_val)\n",
    "\n",
    "class_metrics_df = add_class_metrics(class_metrics_df, xg_class_base, y_pred, y_class_val, 'xg_class_base')\n",
    "class_metrics_df[['model', 'f1_macro', 'kappa']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e31b8e",
   "metadata": {},
   "source": [
    "Interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e16b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print_class_report(y_class_val, y_pred, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix heatmap\n",
    "plot_confusion_matrix(y_class_val, y_pred, class_labels, 'xg_class_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f373ad2f",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e84ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define param grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "xgb = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Grid search with 3-fold CV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "grid_search.fit(X_train, y_class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33334e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "xg_class_tuned = grid_search.best_estimator_\n",
    "xg_best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0952e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "y_pred = rf_class_tuned.predict(X_val)\n",
    "\n",
    "class_metrics_df = add_class_metrics(class_metrics_df, rf_class_tuned, y_pred, y_class_val, 'rf_class_tuned')\n",
    "class_metrics_df[['model', 'f1_macro', 'kappa']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3c8e3c",
   "metadata": {},
   "source": [
    "Interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print_class_report(y_class_val, y_pred, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix heatmap\n",
    "plot_confusion_matrix(y_class_val, y_pred, class_labels, 'rf_class_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725d44d",
   "metadata": {},
   "source": [
    "Interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d6a2fa",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
